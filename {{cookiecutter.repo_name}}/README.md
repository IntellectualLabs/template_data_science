![](docs/images/CompanyLogo.png)

> _This repo structure has been autogenerated from [Intellectual Labs cookiecutter template](https://github.com/IntellectualLabs/data_science_template).
> Feel free to change the company logo under `docs/images/CompanyLogo.png`_

# {{cookiecutter.project_name}}

{{cookiecutter.project_description}}

_Explain the purpose of your repository/project here_

<!-- TOC -->

- [{{cookiecutter.project_name}}](#cookiecutterproject_name)
  - [1. Setup](#1-setup)
    - [1.1 Installation issues](#11-installation-issues)
  - [2. Run API](#2-run-api)
    - [2.1. Option 1: Run API locally](#21-option-1-run-api-locally)
    - [2.2. Option 2: Run API in docker](#22-option-2-run-api-in-docker)
    - [2.3. Option 3: Run API with docker-compose](#23-option-3-run-api-with-docker-compose)
  - [3. Testing](#3-testing)
  - [4. Automated Document Generation](#4-automated-document-generation)
  - [5. References](#5-references)
  <!-- /TOC -->

## 1. Setup

(For the precommit hooks used in this template see: `precommit.md`.)
{% if cookiecutter.python_package_manager == 'poetry' %}
_The setup shows how to set up your environment with the `poetry` python package manager_.

1. Install git and checkout the [git code repository](https://github.com/IntellectualLabs/template_data_science/).
2. Install [Poetry]: <https://python-poetry.org/docs/#installation>
3. Change working directory into the git code repository root
4. Create the self contained environment;

   - _(If the config file `pyproject.toml` does not exist, initialize the environment file `poetry init`.)_
   - Create the env `poetry install`
   - Activate poetry shell `poetry shell`
   - Add packages by `poetry add <package>`.
     - add package as dev package `--dev (-D)`, e.g. `poetry add -D ipykernel` (_already included_)
     - install without dev dependencies `poetry install --no-dev`
   - Update `poetry.lock` without upgrading dependencies: `poetry lock --no-update`

#### 1.1 Installation issues

- If you have any issues installing any python packages
  - especially wheels, try to update pip: `pip install --upgrade pip`
  - Or try upgrading your poetry version: `poetry self update`

{% elif cookiecutter.python_package_manager == 'conda' %}
_The setup shows how to set up your environment with the `conda` python package manager_.

1.  Install git and checkout the [git code repository](https://github.com/IntellectualLabs/template_data_science/).
2.  Install [anaconda] python version 3.8+
3.  Change working directory into the git code repository root
4.  Create the self contained conda environment;

    - Add other necessary packages to `conda_env.yml` under dependencies.
    - Go to the git code repository root and enter the command:

      ```bash
      conda env create --file conda_env.yml
      ```

      - To update run

        ```bash
        conda env update --file conda_env.yml  --prune
        ```

    - Activate the conda environment:

      ```bash
      conda activate {{cookiecutter.project_name.lower().replace(' ', '_')}}
      ```

    - To make the environment available as a kernel in Jupyter notebook,
      install an ipython kernel by

      ```bash
      python -m ipykernel install --user --name {{cookiecutter.project_name.lower().replace(' ', '_')}} --display-name "Python ({{cookiecutter.project_name.lower().replace(' ', '_')}})"
      ```

5.  Any python modules under folder `src/` need to be available to other scripts.
    Install the module locally (in developer mode) in your conda environment with modifications
    reflected immediately:

    ```bash

    pip install -e .

    ```

6.  (_Optional_) Update `requirements.txt`

        ```bash
        conda list -e > requirements.txt
        ```

    {% endif %}

## 2. Run API

In the folder `application/ `, three templates to create web apps and web APIs using Python
are given; using frameworks 1) FastAPI, 2) Dash, 3) Flask. Here we show how to run the
API using FastAPI, with source code in `application/fastapiwebapp/`.

### 2.1. Option 1: Run API locally

To run the API in `application/fastapiwebapp/app.py`, with `root` as working directory run:

```bash
(cd application/fastapiwebapp/ && uvicorn app:app --reload --port 4242)
```

This will run the server and host the api locally on port 4242;
go to http://127.0.0.1:4242/ in your browser.

The API is built using `fastapi` (see [docs](https://fastapi.tiangolo.com/))
which autogenerates API documentation with both Swagger and ReDoc;

1. For Swagger UI API documentation go to http://127.0.0.1:4242/docs
2. For ReDoc UI API documentation go to http://127.0.0.1:4242/redoc

### 2.2. Option 2: Run API in docker

1. Install [Docker](https://www.docker.com/products/docker-desktop)
2. With `root` as working directory, build docker image by:
   ```bash
   docker build -t {{cookiecutter.project_name.lower().replace(' ', '_')}} .
   ```
   Note that this can take several minutes.
3. Spin up a docker container by:
   ```bash
   docker run -it -d --name {{cookiecutter.project_name.lower().replace(' ', '_')}}_api -p 4242:80 {{cookiecutter.project_name.lower().replace(' ', '_')}}
   ```
   This will spin up a container named `{{cookiecutter.project_name.lower().replace(' ', '_')}}_api` which runs the API available at port 4242.
4. To check that the API is up go to http://127.0.0.1:4242/docs (Swagger UI API documentation).

**Tips:** To enter (SSH into) the terminal of the running container:

```bash
docker exec -it {{cookiecutter.project_name.lower().replace(' ', '_')}}_api /bin/bash
```

### 2.3. Option 3: Run API with docker-compose

1. Install [Docker](https://www.docker.com/products/docker-desktop)
2. With `root` as working directory, build docker image by:

   ```bash
   docker-compose -f .\docker-compose-dev.yml --verbose up
   ```

   Note that this can take several minutes.

   This will build the docker image `{{cookiecutter.repo_name}}:latest`
   and spin up a running container on [localhost:8081](localhost:8081) from it for the API.

3. For API documentation (built automatically by FastAPI), go to
   - [localhost:5000/docs](localhost:5000/docs) for documentation provided by Swagger
   - [localhost:5000/redoc](localhost:5000/redoc) for documentation provided by ReDoc

The benefit with running with `docker-compose` is that this is set up to _mount the full repo into the container_,
i.e. all content in the repo (including data and config files) on your local machine (host)
will be mirrored into the container.
Hence any change you make to the source code on your local machine will be automatically
mirrored/changed inside the container as well.
The API is set up to reload when it detects changes, hence all changes to the app
and source code will automatically be available in the running API on [localhost:8081](localhost:8081).

## 3. Testing

Reproducability and the correct functioning of code are essential to avoid wasted time.
If a code block is copied more than once then it should be placed into a
common script / module under `src/` and unit tests added. The same applies for
any other non trivial code to ensure the correct functioning.

To run tests, ensure you have installed the conda environment as explained above
(from `conda_env.yml`) and activated it.
_If not, install `pytest`, `pytest-cookies`, `pytest-cov`,
`pytest-remotedata==0.3.2` using pip or conda._
Then from the repository root run

```bash
pytest tests\
```

To display test coverage of all source code in the folder `src/` run from repository root

```bash
pytest --cov-report term-missing --cov=src tests/
```

For more details, see the README in the folder `tests\`.

## 4. Automated Document Generation

A [sphinx](https://www.sphinx-doc.org/) project is provided under `docs/writeup/` that will generate writeup that
also includes automatically generated API information for any packages. The output can be created in multiple
formats including html and pdf. If you are using CI then this can be run automatically.
To run locally execute the following commands:

```bash
cd docs/writeup
make html
```

On Windows this will run the `make.bat`, a Makefile is also included for those using the `make` command.

## 5. References

- https://github.com/IntellectualLabs/data_science_template
- http://docs.python-guide.org/en/latest/writing/structure/
- https://intellectuallabs.no/

[//]: #
[anaconda]: https://www.continuum.io/downloads
